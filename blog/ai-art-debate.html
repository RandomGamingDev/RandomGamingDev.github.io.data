<div style="display: flex; justify-content: center; padding-top: 50px;">
  <div style="width: fit-content; text-align: center;">
    <img src="https://cdn.pixabay.com/photo/2023/01/13/22/14/ai-art-7717013_1280.jpg" style="padding: 25px;" width="500em">
    <h1 style="padding-bottom: 25px; width: 13em">The AI Art Debate: My Opinion</h1>
  </div>
</div>
<div style="margin: auto; width: 75%; padding: 10px;">
	<p>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The debate concerning the morality of AI art has gone on for quite some time and gained quite a bit of traction. Here, I would like to talk about my personal opinions and arguments for why AI art is not only moral, but also why it should be expanded. I'd also like to remind any zealous anti-AI art preachers to please take this article with a pinch of salt and to not get offended.<br/><br/>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Firstly, we should clear up one point. I am not going to argue that AI doesn't have the chance/ability to, in the future, massively impact industries that involve art in any form or that even just involve other industries that have to do with art. I understand that AI art could take the jobs of some artists, but it's most likely that a lot of artists will keep their jobs or find others due to the nature of the task, just as chess jobs didn't magically dissapear due to the appearance of amazing chess bots. I think that the big picture is more important and that the widespread belief that the removal of AI art will help to protect art and maintain some sort of utopia is simply absurd. <br/><br/>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Let's address one of the main "indisputable facts" that the art community has pushed as a reason for the removal of AI art. They say that AI art simply copys and pastes art from its dataset to create new works, that it's creations are nothing more than an amalgamation of the data shoved inside. I have even heard a multitude of people around me state this! What scares me is that this is being pushed around as some sort of fact among those that don't even understand the inner workings of these sorts of algorithms. I feel that, had a lot of these done their research on the inner workings of the things that they so zealously preached against, that a lot of them wouldn't be on the side of the argument that they're currently on.<br/><br/>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For those who don't understand the inner workings of these machines, I'll give a very quick and basic summary (which means that you still need to do more research than a tiny article on the internet) (the links I put over words like "machine learning" would be a great path to getting there). These machines operate using neural networks, yes, they operate off of neurons, which operate off of the same principles as biological neurons in the minds of you and me (well probably you, I can't be quite too sure that it isn't an AI reading this right now). Using these neurons they're able to learn, in a process referred to as <a href="https://en.wikipedia.org/wiki/Machine_learning" target="_blank" style="text-decoration: underline;">machine learning</a>, more specifically a form of machine learning called <a href="https://en.wikipedia.org/wiki/Deep_learning" target="_blank" style="text-decoration: underline;">deep learning</a>. Now you might say "Oh yeah sure, they learn and think with neurons and information just like humans do, but they're still copying and pasting those drawings aren't they?", and to that too I ask that you do more research on your part random imaginary reading that I envisioned in the writing of this article. Image generation AIs like DALL-E, Stable Diffusion and Midjourney are <a href="https://en.wikipedia.org/wiki/Diffusion_model" target="_blank" style="text-decoration: underline;">diffusion models</a> which is a type of <a href="https://en.wikipedia.org/wiki/Latent_variable_model" target="_blank" style="text-decoration: underline;">latent variable model</a>. What does all of this mean? You may ask. Now, I don't have the patience to write a full research paper, but in summary, image generation AIs, when training take images from their dataset, which get a certain amount of noise added to them, which the AI then tries to restore with the help of added information from a text prompt. When the AI gets good enough at this the AI will be released to the public, where, instead of getting jumbled images the AI instead gets pure randomness, which the AI tries to reconstruct an image out of. By doing this it isn't taking any parts of any works used in any of its training routines, but rather attempting to reconstruct nothing, which is something that you may be quite familiar with if you've dealt with art before. Yes dear reader, we call that drawing.<br/><br/>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Of course to this many would argue that AI can resconstruct those works if you get the prompt just right and that even i the AI is drawing something unique, that the data of the works it was trained on being inside of the AI itself is immoral. To that I ask what would you do if you got the exact description of an art piece you remember and had no other input? What drawings would anyone draw if it hadn't been for the images we see throughout our life experiences? To both of those, there's only one answer, that you would do what the AI did. "Oh yeah I have this painting I remember! Let me reconstruct it, cause it'll be easier than remaking something!" and "None." AI is simply doing what a human would, with information that's simply what a human would see, thus why make it so that human can use this data, when AI can't?<br/><br/>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Here's something different for you to think about. Have you heard of AIs trying to solve a multitude of humanity's problems? For example, AI screening for health problems in images/screenings of patients, trained off of patient data, from not only the patients, but the doctors themselves. You most likely have. Now imagine if the doctors got angry at the AI for using their work, work they aren't even posting it freely online for that matter. Most would respond that the doctors are greedy wouldn't they? People rebelling against losing their jobs, which likely feed not only them, but those close them isn't the greedy part, but trying to stop the AI is, as healthcare should be accessible to all, just as I understand that artists trying to prevent the loss of their jobs isn't greedy, but that the act of attempting to stop AI would be. Stopping AI quite clearly is not the answer. Instead a better solution must be found, a topic that I won't go further into due to the nuances of the topic. I believe that supporting a high quality of life and more possibilities for all is something that should be heavily strived for, which is the reason why stopping the AI in of itself is immoral. Imagine a world where even those who might not be able to draw or get someone who can, can create works of art, whether for books, articles, games and other sorts of media. That would be the true utopia wouldn't it?<br/><br/>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Now consider modern times. And then past times a couple centuries back. You can see a clear improvement in the quality of life from back then till now. Why? Well technology! Countless may have lost their jobs, but countless more have lived to tell a tale, of a quality of life never before seen anywhere, of an utopia. The simple thing is, that the progression of technology is inevitable and positive, and stopping it is not only not positive, but immoral in every sense of the word. This is why image generation AI should stay rather than go.
</p>
</div>
